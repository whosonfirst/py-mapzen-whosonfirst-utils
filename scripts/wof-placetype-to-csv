#!/usr/bin/env python

import sys
import logging
import os.path
import csv
import pprint
import geojson
import time
import shutil
import hashlib

import mapzen.whosonfirst.utils
import mapzen.whosonfirst.meta
import mapzen.whosonfirst.placetypes

if __name__ == '__main__':

    import optparse
    opt_parser = optparse.OptionParser()

    opt_parser.add_option('-R', '--repo', dest='repo', action='store', default=None, help='Path to a valid WOF repo - this takes precedence over options.source, options.csv and options.name-template and assumes that options.repo has both a data and a meta directory')

    opt_parser.add_option('-s', '--source', dest='source', action='store', default=None, help='Directory to read files from')
    opt_parser.add_option('-c', '--csv', dest='csv', action='store', default=None, help='Directory to write concordances to (default is STDOUT)')

    opt_parser.add_option('-p', '--placetypes', dest='placetypes', action='store', default=None, help='')
    opt_parser.add_option('-r', '--roles', dest='roles', action='store', default=None, help='')
    opt_parser.add_option('-l', '--latest', dest='latest', action='store_true', default=False, help='Copy <PLACETYPE>-<YMD>.csv to <PLACETYPE>-latest.csv (default is False)')
    opt_parser.add_option('-n', '--name-template', dest='name_template', action='store', default=None, help='Apply this (Python string) template to each placetype in order to generate the bundle name')

    opt_parser.add_option('-v', '--verbose', dest='verbose', action='store_true', default=False, help='Be chatty (default is false)')
    options, args = opt_parser.parse_args()

    if options.verbose:	
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)

    #

    placetypes = []

    if options.placetypes:

        for pt in options.placetypes.split(","):
            pt = pt.strip()

            if not mapzen.whosonfirst.placetypes.is_valid_placetype(pt):
                logging.error("Invalid placetype (%s)" % pt)
                sys.exit()

        placetypes.append(pt)

    elif options.roles:

        roles = []

        for rl in options.roles.split(","):

            rl = rl.strip()

            if not mapzen.whosonfirst.placetypes.is_valid_role(rl):
                logging.error("Invalid role (%s)" % (rl))
                sys.exit()

            roles.append(rl)

        placetypes = mapzen.whosonfirst.placetypes.with_roles(roles)        

    else:

        placetypes = mapzen.whosonfirst.placetypes.with_roles(('common', 'common_optional', 'optional'))

    #

    src = options.source
    dest = options.csv

    name_template = options.name_template

    if options.repo:

        repo = os.path.abspath(options.repo)

        data = os.path.join(repo, "data")
        meta = os.path.join(repo, "meta")

        for path in (data, meta):

            if not os.path.exists(path):
                logging.error("%s does not exist!" % path)
                sys.exit(1)

        src = data
        dest = meta

        repo_name = os.path.basename(repo)
        repo_name = repo_name.replace("whosonfirst-data", "")
        repo_name = repo_name.lstrip("-")

        repo_name = repo_name.split("-")
        repo_name[0] = "%s"

        name_template = "-".join(repo_name)

    #

    handles = {}
    writers = {}
    paths = {}
    preexisting = []

    # first create file handles and paths for each placetype

    for pt in placetypes:

        name = pt

        if name_template:
            name = name_template % name

        if not dest:
            handles[name] = sys.stdout
            paths[name] = None
            continue

        root = os.path.abspath(dest)

        now = time.gmtime()
        ymd = time.strftime("%Y%m%d", now)

        fname = "wof-%s-%s.csv" % (name, ymd)
        outpath = os.path.join(root, fname)

        # Are we writing this file for the first time? This becomes
        # relevant if/when we are trying to clean up '-latest' files
        # below (20151110/thisisaaronland)

        if os.path.exists(outpath):
            preexisting.append(outpath)

        outfh = open(outpath, 'w')

        handles[name] = outfh
        paths[name] = outpath
    
    # now create a CSV writer for each placetype

    for name, fh in handles.items():

        fn = mapzen.whosonfirst.meta.fieldnames()

        writer = csv.DictWriter(fh, fieldnames=fn)
        writer.writeheader()
        writers[name] = writer

    # start crawling... and remember we are crawling all the things

    source = os.path.abspath(src)
    crawl = mapzen.whosonfirst.utils.crawl(source)

    meta_kwargs = {
        'paths': 'relative',
        'prefix': source,
        }

    for path in crawl:

        out = mapzen.whosonfirst.meta.dump_file(path, **meta_kwargs)
        name = out['placetype']

        if name_template:
            name = name_template % name

        writer = writers.get(name, None)

        if not writer:

            if not options.placetypes:
                logging.error("Missing a filehandle for writing records of placetype %s (%s), perhaps you need to update your copy of mapzen.whosonfirst.placetypes" % (placetype, path))

            continue

        writer.writerow(out)

    for ignore, fh in handles.items():
        fh.close()

    if options.latest:

        for name, path in paths.items():
            
            root = os.path.abspath(options.csv)
            fname = "wof-%s-latest.csv" % name
            latest_path = os.path.join(root, fname)

            is_new = True

            # https://github.com/whosonfirst/py-mapzen-whosonfirst-utils/issues/3

            if os.path.exists(latest_path):

                # TBD - PUT ALL THIS LOGIC INSIDE OF mz.wof.meta

                ymd_hash = mapzen.whosonfirst.meta.hash_file(path)
                latest_hash = mapzen.whosonfirst.meta.hash_file(latest_path)

                if ymd_hash == latest_hash:
                    logging.info("%s already exists and it is the same as %s" % (latest_path, path))
                    is_new = False

            # shiny and chrome!

            if is_new:
                logging.info("copy %s to %s" % (path, latest_path))
                shutil.copy(path, latest_path)

            # recycle all the bytes

            elif not path in preexisting:
                logging.info("removing %s because it is redundant" % path)
                os.unlink(path)

            # basically a no-op but it's too late to do anything about it

            else:
                logging.debug("ALL OF THIS HAS HAPPENED BEFORE")
                pass

    sys.exit()
